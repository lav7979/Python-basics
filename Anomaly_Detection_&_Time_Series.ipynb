{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOWyu5S+qfuphLcIrTVAbMA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lav7979/Python-basics/blob/main/Anomaly_Detection_%26_Time_Series.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rs32c4bL9uS7"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "1 : What is Anomaly Detection? Explain its types (point, contextual, and\n",
        "collective anomalies) with examples?\n",
        "\n",
        "\n",
        "\n",
        "        Anomaly Detection is the process of identifying data points, patterns, or events that deviate significantly from the majority of the data. These deviations are known as anomalies, outliers, or exceptions, and they often indicate critical incidents like:\n",
        "\n",
        "\n",
        "            Fraud (e.g., credit card fraud)\n",
        "\n",
        "            Equipment failures (e.g., machinery fault detection)\n",
        "\n",
        "            Network intrusions\n",
        "\n",
        "            Medical conditions (e.g., detecting disease from patient data)\n",
        "\n",
        "             Types of Anomalies\n",
        "\n",
        "            Anomalies are usually categorized into three types:\n",
        "\n",
        "            1. Point Anomaly\n",
        "\n",
        "            A point anomaly occurs when a single data point is significantly different from the rest of the data.\n",
        "\n",
        "\n",
        "\n",
        ":\n",
        "              Consider temperature data over a week:\n",
        "\n",
        "              [22, 23, 22, 21, 90, 22, 23]\n",
        "\n",
        "\n",
        "              Here, 90 is a point anomaly, because itâ€™s unusually high compared to the rest of the data (around 21â€“23Â°C).\n",
        "\n",
        "               Use case: Credit card fraud â€” A $10,000 charge on a card that usually has <$100 transactions.\n",
        "\n",
        "              2. Contextual Anomaly (aka Conditional Anomaly)\n",
        "\n",
        "              A contextual anomaly is a data point that is only anomalous in a specific context (such as time or location).\n",
        "\n",
        "             \n",
        "              Temperature readings across different seasons:\n",
        "\n",
        "              Winter: [2, 1, 3, 2, 25]\n",
        "\n",
        "\n",
        "              Here, 25Â°C is a contextual anomaly in winter, but may be normal in summer.\n",
        "\n",
        "               Use case: Web traffic spikes during holidays may be normal in December but anomalous in July.\n",
        "\n",
        "              3. Collective Anomaly\n",
        "\n",
        "              A collective anomaly refers to a group of data points that together represent an anomaly, even if individual points might not be anomalous.\n",
        "\n",
        "             \n",
        "              Network traffic:\n",
        "\n",
        "              [10, 12, 11, 200, 220, 210, 12, 13]\n",
        "\n",
        "\n",
        "        The values [200, 220, 210] are a collective anomaly â€” they indicate a sudden surge (possibly a DDoS attack) even if each point is not too unusual on its own.\n",
        "\n",
        "      Use case: A group of abnormal signals in an ECG may indicate a heart problem.\n",
        "\n",
        "         Output\n",
        "\n",
        "\n",
        "        Type\tDescription\tExample\tUse Case\n",
        "        Point Anomaly\tSingle unusual data point\t[22, 23, 90, 22] â†’ 90 is odd\tCredit card fraud\n",
        "        Contextual\tUnusual in a specific context\t25Â°C in winter\tSeasonal temperature checks\n",
        "        Collective\tA group of anomalies together form the abnormality\t[200, 220, 210] spike in data\tCyberattack detection.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "2: Compare Isolation Forest, DBSCAN, and Local Outlier Factor in terms of\n",
        "their approach and suitable use cases?\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "              Based on the idea that anomalies are few and different.\n",
        "\n",
        "              Uses random forests to isolate observations by randomly selecting a feature and a split value.\n",
        "\n",
        "              Anomalies are isolated faster (i.e., fewer splits needed).\n",
        "\n",
        "              \n",
        "              High-dimensional datasets\n",
        "\n",
        "              Large datasets\n",
        "\n",
        "              Global outlier detection\n",
        "\n",
        "              \n",
        "\n",
        "              Fraud detection in financial transactions\n",
        "\n",
        "              Server performance monitoring\n",
        "\n",
        "               2. DBSCAN (Density-Based Spatial Clustering of Applications with Noise)\n",
        "               Approach:\n",
        "\n",
        "              A clustering algorithm that groups points with many nearby neighbors.\n",
        "\n",
        "              Points in low-density regions (few neighbors) are marked as outliers.\n",
        "\n",
        "              Based on density (Îµ-neighborhood and minPts).\n",
        "\n",
        "              \n",
        "\n",
        "              Low-dimensional data\n",
        "\n",
        "              Data with spatial or geographical context\n",
        "\n",
        "              Detecting clusters and noise\n",
        "\n",
        "              \n",
        "\n",
        "              GPS trajectory anomaly detection\n",
        "\n",
        "              Clustering and detecting noise in customer location data\n",
        "\n",
        "             \n",
        "               Approach:\n",
        "\n",
        "              Measures the local density of a point compared to its neighbors.\n",
        "\n",
        "              Points that have significantly lower density than their neighbors are considered outliers.\n",
        "\n",
        "              Good at finding local anomalies.\n",
        "\n",
        "              \n",
        "\n",
        "              Complex local structures\n",
        "\n",
        "              When detecting contextual or local anomalies\n",
        "\n",
        "              \n",
        "\n",
        "              Anomaly detection in sensor networks\n",
        "\n",
        "              Detecting abnormal user behavior in a small group\n",
        "\n",
        " Output;\n",
        "\n",
        "\n",
        "\n",
        "          Feature / Method\tIsolation Forest\tDBSCAN\tLocal Outlier Factor (LOF)\n",
        "          Approach\tTree-based isolation\tDensity-based clustering\tLocal density-based scoring\n",
        "          Type\tGlobal anomaly detector\tClustering + noise detection\tLocal anomaly detector\n",
        "          Best For\tHigh-dimensional, large data\tSpatial/geographic data\tData with local patterns or varying densities\n",
        "          Handles Noise\tYes\tYes (marks as noise)\tYes\n",
        "          Scales to Big Data\t (Efficient and fast)\t (Slower on large datasets)\t (Computationally expensive)\n",
        "          Parameter Sensitivity\tLow\tHigh (Îµ, minPts)\tHigh (k - number of neighbors)\n",
        "          Output\tAnomaly score per point\tClusters + Noise\tAnomaly score per point\n",
        "          Use Case Example\tFraud detection, system monitoring\tGPS outlier detection\tAbnormal sensor readings, localized fraud.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "     3  What are the key components of a Time Series? Explain each with one\n",
        "example?\n",
        "\n",
        "\n",
        "\n",
        "        A Time Series is a sequence of data points collected or recorded at regular time intervals, e.g., hourly, daily, monthly.\n",
        "\n",
        "\n",
        "            Key Components of a Time Series:\n",
        "            1. Trend (T)\n",
        "\n",
        "            Definition: The long-term increasing or decreasing movement in the data over time.\n",
        "\n",
        "\n",
        "            Monthly sales data of a company over 5 years:\n",
        "\n",
        "            [100, 120, 140, 160, 180, 200...]\n",
        "\n",
        "\n",
        "            Shows a consistent upward trend.\n",
        "\n",
        "             Interpretation: Business is growing steadily over time.\n",
        "\n",
        "            2. Seasonality (S)\n",
        "\n",
        "             Definition: Regular and periodic fluctuations in the data due to seasonal effects (daily, weekly, monthly, yearly).\n",
        "\n",
        "            \n",
        "            Ice cream sales over 12 months:\n",
        "\n",
        "            [50, 60, 70, 80, 100, 120, 130, 110, 90, 60, 50, 40]\n",
        "\n",
        "\n",
        "            Sales peak in summer months â€” this is seasonality.\n",
        "\n",
        "             Interpretation: Sales depend on the season/weather.\n",
        "\n",
        "            3. Cyclic (C)\n",
        "\n",
        "             Definition: Long-term fluctuations in data that occur over irregular intervals, often tied to business or economic cycles.\n",
        "\n",
        "            \n",
        "            Unemployment rate over 10 years:\n",
        "\n",
        "            Fluctuates due to economic cycles (recession, boom, etc.)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "4  Define Stationary in time series. How can you test and transform a\n",
        "non-stationary series into a stationary one?\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "              A time series is said to be stationary if its statistical properties â€” such as mean, variance, and autocorrelation â€” do not change over time.\n",
        "\n",
        "               Why Stationarity Matters:\n",
        "\n",
        "              Most time series models (like ARIMA) assume stationarity, because:\n",
        "\n",
        "              It's easier to model.\n",
        "\n",
        "              Forecasts from stationary models are more reliable and consistent.\n",
        "\n",
        "               Types of Stationarity\n",
        "              Type\tDescription\n",
        "              Strict Stationarity\tFull statistical distribution doesnâ€™t change over time.\n",
        "              Weak Stationarity\tMean, variance, and autocovariance stay constant.\n",
        "\n",
        "               Most practical applications use weak stationarity.\n",
        "\n",
        "               How to Test for Stationarity\n",
        "              1. Visual Inspection\n",
        "\n",
        "              Plot the time series.\n",
        "\n",
        "              Look for changing mean or variance over time.\n",
        "\n",
        "              2. Statistical Tests\n",
        "              a) ADF (Augmented Dickey-Fuller) Test\n",
        "\n",
        "              Null Hypothesis (Hâ‚€): Series is non-stationary\n",
        "\n",
        "              Alternative Hypothesis (Hâ‚): Series is stationary\n",
        "\n",
        "              If p-value < 0.05 â†’ Reject Hâ‚€ â†’ Series is stationary\n",
        "\n",
        "              b) KPSS Test (Kwiatkowskiâ€“Phillipsâ€“Schmidtâ€“Shin)\n",
        "\n",
        "              Opposite to ADF:\n",
        "\n",
        "              Null Hypothesis (Hâ‚€): Series is stationary\n",
        "\n",
        "              Alternative Hypothesis (Hâ‚): Series is non-stationary\n",
        "\n",
        "               How to Transform a Non-Stationary Series into a Stationary One\n",
        "              Method\tDescription\tExample\n",
        "              Differencing\tSubtract current value from previous value: y(t) - y(t-1)\tRemoves trend\n",
        "              Log Transformation\tStabilizes variance\tGood for exponential growth\n",
        "              Detrending\tSubtract estimated trend component\tUseful when trend is predictable\n",
        "              Seasonal Adjustment\tRemove seasonal effect using decomposition\tUseful with seasonal patterns\n",
        "\n",
        "\n",
        "\n",
        " Output:\n",
        "\n",
        "\n",
        "        Step\tTool/Method\tInterpretation/Action\n",
        "        Check Stationarity\tPlot, ADF test, KPSS test\tVisual or statistical test for stationarity\n",
        "        If Non-stationary\tDifferencing, log, detrending\tApply transformation\n",
        "        Recheck\tADF/KPSS after transformation\tConfirm series is now stationary\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "5 Differentiate between AR, MA, ARIMA, SARIMA, and SARIMAX models in\n",
        "terms of structure and application?\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "                  Structure:\n",
        "\n",
        "                  Forecasts future values based on past values (lags).\n",
        "\n",
        "                  Denoted as AR(p):\n",
        "\n",
        "                  ð‘Œ\n",
        "                  ð‘¡\n",
        "                  =\n",
        "                  ð‘\n",
        "                  +\n",
        "                  ðœ™\n",
        "                  1\n",
        "                  ð‘Œ\n",
        "                  ð‘¡\n",
        "                  âˆ’\n",
        "                  1\n",
        "                  +\n",
        "                  ðœ™\n",
        "                  2\n",
        "                  ð‘Œ\n",
        "                  ð‘¡\n",
        "                  âˆ’\n",
        "                  2\n",
        "                  +\n",
        "                  .\n",
        "                  .\n",
        "                  .\n",
        "                  +\n",
        "                  ðœ™\n",
        "                  ð‘\n",
        "                  ð‘Œ\n",
        "                  ð‘¡\n",
        "                  âˆ’\n",
        "                  ð‘\n",
        "                  +\n",
        "                  ðœ–\n",
        "                  ð‘¡\n",
        "                  Y\n",
        "                  t\n",
        "                    â€‹\n",
        "\n",
        "                  =c+Ï•\n",
        "                  1\n",
        "                    â€‹\n",
        "\n",
        "                  Y\n",
        "                  tâˆ’1\n",
        "                    â€‹\n",
        "\n",
        "                  +Ï•\n",
        "                  2\n",
        "                    â€‹\n",
        "\n",
        "                  Y\n",
        "                  tâˆ’2\n",
        "                    â€‹\n",
        "\n",
        "                  +...+Ï•\n",
        "                  p\n",
        "                    â€‹\n",
        "\n",
        "                  Y\n",
        "                  tâˆ’p\n",
        "                    â€‹\n",
        "\n",
        "                  +Ïµ\n",
        "                  t\n",
        "                    â€‹\n",
        "\n",
        "                 \n",
        "\n",
        "                  When there is strong autocorrelation (past values influence the future).\n",
        "\n",
        "                  E.g., predicting stock prices using past prices.\n",
        "\n",
        "                   2. MA (Moving Average) Model\n",
        "                   Structure:\n",
        "\n",
        "                  Models the error term as a linear combination of past forecast errors.\n",
        "\n",
        "                  Denoted as MA(q):\n",
        "\n",
        "                  ð‘Œ\n",
        "                  ð‘¡\n",
        "                  =\n",
        "                  ð‘\n",
        "                  +\n",
        "                  ðœ–\n",
        "                  ð‘¡\n",
        "                  +\n",
        "                  ðœƒ\n",
        "                  1\n",
        "                  ðœ–\n",
        "                  ð‘¡\n",
        "                  âˆ’\n",
        "                  1\n",
        "                  +\n",
        "                  ðœƒ\n",
        "                  2\n",
        "                  ðœ–\n",
        "                  ð‘¡\n",
        "                  âˆ’\n",
        "                  2\n",
        "                  +\n",
        "                  .\n",
        "                  .\n",
        "                  .\n",
        "                  +\n",
        "                  ðœƒ\n",
        "                  ð‘ž\n",
        "                  ðœ–\n",
        "                  ð‘¡\n",
        "                  âˆ’\n",
        "                  ð‘ž\n",
        "                  Y\n",
        "                  t\n",
        "                    â€‹\n",
        "\n",
        "                  =c+Ïµ\n",
        "                  t\n",
        "                    â€‹\n",
        "\n",
        "                  +Î¸\n",
        "                  1\n",
        "                    â€‹\n",
        "\n",
        "                  Ïµ\n",
        "                  tâˆ’1\n",
        "                    â€‹\n",
        "\n",
        "                  +Î¸\n",
        "                  2\n",
        "                    â€‹\n",
        "\n",
        "                  Ïµ\n",
        "                  tâˆ’2\n",
        "                    â€‹\n",
        "\n",
        "                  +...+Î¸\n",
        "                  q\n",
        "                    â€‹\n",
        "\n",
        "                  Ïµ\n",
        "                  tâˆ’q\n",
        "                    â€‹\n",
        "\n",
        "                  \n",
        "\n",
        "                  When the noise (errors) in data is autocorrelated.\n",
        "\n",
        "                  E.g., smoothing out a noisy sensor reading.\n",
        "\n",
        "                   3. ARIMA (AutoRegressive Integrated Moving Average)\n",
        "                   Structure:\n",
        "\n",
        "                  Combines AR and MA, with Integration (differencing) to make the series stationary.\n",
        "\n",
        "                  Denoted as ARIMA(p, d, q):\n",
        "\n",
        "                  p: autoregressive terms\n",
        "\n",
        "                  d: order of differencing\n",
        "\n",
        "                  q: moving average terms\n",
        "\n",
        "                  ð‘Œ\n",
        "                  ð‘¡\n",
        "                  â€²\n",
        "                  =\n",
        "                  ð‘\n",
        "                  +\n",
        "                  ðœ™\n",
        "                  ð‘Œ\n",
        "                  ð‘¡\n",
        "                  âˆ’\n",
        "                  1\n",
        "                  â€²\n",
        "                  +\n",
        "                  ðœƒ\n",
        "                  ðœ–\n",
        "                  ð‘¡\n",
        "                  âˆ’\n",
        "                  1\n",
        "                  +\n",
        "                  ðœ–\n",
        "                  ð‘¡\n",
        "                  Y\n",
        "                  t\n",
        "                  â€²\n",
        "                    â€‹\n",
        "\n",
        "                  =c+Ï•Y\n",
        "                  tâˆ’1\n",
        "                  â€²\n",
        "                    â€‹\n",
        "\n",
        "                  +Î¸Ïµ\n",
        "                  tâˆ’1\n",
        "                    â€‹\n",
        "\n",
        "                  +Ïµ\n",
        "                  t\n",
        "                    â€‹\n",
        "\n",
        "\n",
        "                  (Where\n",
        "                  ð‘Œ\n",
        "                  ð‘¡\n",
        "                  â€²\n",
        "                  Y\n",
        "                  t\n",
        "                  â€²\n",
        "                    â€‹\n",
        "\n",
        "                  is the differenced series)\n",
        "\n",
        "                   Use Case:\n",
        "\n",
        "                  Non-stationary time series (trend present, but no seasonality).\n",
        "\n",
        "                  E.g., Forecasting sales, temperature, or stock prices.\n",
        "\n",
        "                   4. SARIMA (Seasonal ARIMA)\n",
        "                   Structure:\n",
        "\n",
        "                  Extends ARIMA to handle seasonality.\n",
        "\n",
        "                  Denoted as SARIMA(p, d, q)(P, D, Q, s):\n",
        "\n",
        "                  Seasonal components: P, D, Q\n",
        "\n",
        "                  s: season length (e.g., 12 for monthly data)\n",
        "\n",
        "                   Use Case:\n",
        "\n",
        "                  Seasonal and non-stationary time series.\n",
        "\n",
        "                  E.g., Monthly airline passenger data, retail sales.\n",
        "\n",
        "                   5. SARIMAX (SARIMA with eXogenous variables)\n",
        "                   Structure:\n",
        "\n",
        "                  SARIMA + external (exogenous) variables (X).\n",
        "\n",
        "                  Adds the ability to model the effect of other variables on the target.\n",
        "\n",
        "                  ð‘Œ\n",
        "                  ð‘¡\n",
        "                  =\n",
        "                  ð‘†\n",
        "                  ð´\n",
        "                  ð‘…\n",
        "                  ð¼\n",
        "                  ð‘€\n",
        "                  ð´\n",
        "                  _\n",
        "                  ð‘š\n",
        "                  ð‘œ\n",
        "                  ð‘‘\n",
        "                  ð‘’\n",
        "                  ð‘™\n",
        "                  +\n",
        "                  ð›½\n",
        "                  ð‘‹\n",
        "                  ð‘¡\n",
        "                  +\n",
        "                  ðœ–\n",
        "                  ð‘¡\n",
        "                  Y\n",
        "                  t\n",
        "                    â€‹\n",
        "\n",
        "                  =SARIMA_model+Î²X\n",
        "                  t\n",
        "                    â€‹\n",
        "\n",
        "                  +Ïµ\n",
        "                  t\n",
        "                    â€‹\n",
        "\n",
        "                  \n",
        "\n",
        "                  Seasonal time series affected by other variables.\n",
        "\n",
        "                  E.g., Sales influenced by advertising budget or holidays.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        " Output;\n",
        "\n",
        "\n",
        "        Model\tComponents\tHandles Trend\tHandles Seasonality\tIncludes External Variables\tCommon Use Case\n",
        "        AR\tPast values (lags)\t\tStock price prediction (short term)\n",
        "        MA\tPast errors\t\tNoise smoothing\n",
        "        ARIMA\tAR + I (differencing) + MA\tSales, temperature forecasting\n",
        "        SARIMA\tARIMA + Seasonal components\t\tRetail or airline demand (monthly/quarterly)\n",
        "        SARIMAX\tSARIMA + Exogenous variables\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "6  Load a time series dataset , plot the original series,\n",
        "and decompose it into trend, seasonality, and residual components.?\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "              import pandas as pd\n",
        "              import matplotlib.pyplot as plt\n",
        "              from statsmodels.tsa.seasonal import seasonal_decompose\n",
        "\n",
        "              # Step 1: Load AirPassengers dataset (monthly totals of international airline passengers, 1949â€“1960)\n",
        "              url = 'https://raw.githubusercontent.com/jbrownlee/Datasets/master/airline-passengers.csv'\n",
        "              df = pd.read_csv(url, parse_dates=['Month'], index_col='Month')\n",
        "\n",
        "              # Step 2: Plot the original time series\n",
        "              plt.figure(figsize=(10, 4))\n",
        "              plt.plot(df, label='Monthly Passengers')\n",
        "              plt.title('Original AirPassengers Time Series')\n",
        "              plt.xlabel('Date')\n",
        "              plt.ylabel('Passengers')\n",
        "              plt.legend()\n",
        "              plt.grid(True)\n",
        "              plt.tight_layout()\n",
        "              plt.show()\n",
        "\n",
        "              # Step 3: Decompose the time series\n",
        "              decomposition = seasonal_decompose(df['Passengers'], model='multiplicative', period=12)\n",
        "\n",
        "              # Step 4: Plot decomposition\n",
        "              decomposition.plot()\n",
        "              plt.suptitle('Decomposition of AirPassengers Time Series', fontsize=16)\n",
        "              plt.tight_layout()\n",
        "              plt.show()\n",
        "\n",
        " Output;\n",
        "\n",
        "\n",
        "          Original Time Series:\n",
        "\n",
        "          Shows clear upward trend.\n",
        "\n",
        "          Exhibits seasonal spikes around the same months each year.\n",
        "\n",
        "          Decomposition Components:\n",
        "\n",
        "          Trend: Long-term growth in air travel.\n",
        "\n",
        "          Seasonality: Regular annual patterns (e.g., peaks in summer).\n",
        "\n",
        "          Residual: Irregular/random variations after removing trend and seasonality.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "7  Apply Isolation Forest on a numerical dataset (e.g., NYC Taxi Fare) to\n",
        "detect anomalies. Visualize the anomalies on a 2D scatter plot?\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "                  import pandas as pd\n",
        "                  import numpy as np\n",
        "                  import matplotlib.pyplot as plt\n",
        "                  from sklearn.ensemble import IsolationForest\n",
        "                  from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "                  # Step 1: Load a sample of the NYC Taxi Fare data\n",
        "                  # (Assume we have a CSV with columns: trip_distance, fare_amount)\n",
        "                  df = pd.read_csv('nyc_taxi_fares_sample.csv')\n",
        "\n",
        "                  # Step 2: Keep only numeric features for anomaly detection\n",
        "                  # We'll use trip_distance and fare_amount as two features\n",
        "                  features = df[['trip_distance', 'fare_amount']].copy()\n",
        "\n",
        "                  # Step 3: Clean/filter data (remove non-positive values, extreme extremes etc.)\n",
        "                  features = features[(features['trip_distance'] > 0) & (features['fare_amount'] > 0)]\n",
        "                  # Optionally clip or remove extremely large values\n",
        "                  features = features[features['trip_distance'] < 100]  # example cap\n",
        "                  features = features[features['fare_amount'] < 500]     # example cap\n",
        "\n",
        "                  # Step 4: Scale features\n",
        "                  scaler = StandardScaler()\n",
        "                  X_scaled = scaler.fit_transform(features)\n",
        "\n",
        "                  # Step 5: Fit Isolation Forest\n",
        "                  iso = IsolationForest(n_estimators=100, contamination=0.01, random_state=42)\n",
        "                  iso.fit(X_scaled)\n",
        "\n",
        "                  # Step 6: Predict anomalies\n",
        "                  pred = iso.predict(X_scaled)  # returns 1 for inliers, -1 for anomalies\n",
        "                  features['anomaly'] = pred\n",
        "\n",
        "                  # Step 7: Plotting\n",
        "                  plt.figure(figsize=(10, 6))\n",
        "                  # Plot inliers\n",
        "                  inliers = features[features['anomaly'] == 1]\n",
        "                  plt.scatter(inliers['trip_distance'], inliers['fare_amount'],\n",
        "                              c='blue', label='Inliers', alpha=0.6)\n",
        "                  # Plot anomalies\n",
        "                  anoms = features[features['anomaly'] == -1]\n",
        "                  plt.scatter(anoms['trip_distance'], anoms['fare_amount'],\n",
        "                              c='red', label='Anomalies', edgecolors='k', s=50)\n",
        "                  plt.xlabel('Trip Distance (scaled back or raw)')\n",
        "                  plt.ylabel('Fare Amount')\n",
        "                  plt.title('Isolation Forest Anomalies: NYC Taxi Fare vs Trip Distance')\n",
        "                  plt.legend()\n",
        "                  plt.show()\n",
        "\n",
        "\n",
        "            Hypothetical Output & Interpretation\n",
        "            Imagine the plot and observations look like this:\n",
        "\n",
        "            The scatter plot shows most points clustered in the bottom-left area: short trips with moderate fares.\n",
        "\n",
        "            A few red points (anomalies) are far away: e.g., either high fare for short distance, or very large distance but low fare, or fares far above typical for given distances.\n",
        "\n",
        "            Perhaps we see anomalies like:\n",
        "\n",
        "            A trip of 0.5 miles but fare = $200 (maybe erroneous input or data glitch).\n",
        "\n",
        "            A trip of 50 miles but fare = $2 (obviously wrong).\n",
        "\n",
        "            Very long trips with very high fare, but beyond normal limits.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        " Output ;\n",
        "\n",
        "\n",
        "\n",
        "        Feature Pair\tValue for Inliers Range\tExample Anomalous Point\n",
        "        trip_distance\t0.1 â€” 30 miles\t60 miles\n",
        "        fare_amount\t$2 â€” $60\t$200 or $1\n",
        "        fare_amount per mile\troughly $1 to $4 per mile\t$100 per mile or $0.01/mile.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "8 Train a SARIMA model on the monthly airline passengers dataset.\n",
        "Forecast the next 12 months and visualize the results?\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "                  import pandas as pd\n",
        "                  import matplotlib.pyplot as plt\n",
        "                  from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
        "                  from pandas.plotting import register_matplotlib_converters\n",
        "\n",
        "                  register_matplotlib_converters()\n",
        "\n",
        "                  # Step 1: Load the AirPassengers dataset\n",
        "                  url = 'https://raw.githubusercontent.com/jbrownlee/Datasets/master/airline-passengers.csv'\n",
        "                  df = pd.read_csv(url, parse_dates=['Month'], index_col='Month')\n",
        "                  df.columns = ['Passengers']\n",
        "\n",
        "                  # Step 2: Fit SARIMA model\n",
        "                  # SARIMA(p,d,q)(P,D,Q,s), s=12 for monthly seasonality\n",
        "                  model = SARIMAX(df['Passengers'],\n",
        "                                  order=(1, 1, 1),\n",
        "                                  seasonal_order=(1, 1, 1, 12),\n",
        "                                  enforce_stationarity=False,\n",
        "                                  enforce_invertibility=False)\n",
        "                  results = model.fit()\n",
        "\n",
        "                  # Step 3: Forecast next 12 months\n",
        "                  forecast = results.get_forecast(steps=12)\n",
        "                  forecast_index = pd.date_range(start=df.index[-1] + pd.DateOffset(months=1), periods=12, freq='MS')\n",
        "                  forecast_mean = forecast.predicted_mean\n",
        "                  forecast_ci = forecast.conf_int()\n",
        "\n",
        "                  # Step 4: Plot results\n",
        "                  plt.figure(figsize=(10, 6))\n",
        "                  plt.plot(df.index, df['Passengers'], label='Historical')\n",
        "                  plt.plot(forecast_index, forecast_mean, color='green', label='Forecast')\n",
        "                  plt.fill_between(forecast_index,\n",
        "                                  forecast_ci.iloc[:, 0],\n",
        "                                  forecast_ci.iloc[:, 1],\n",
        "                                  color='lightgreen', alpha=0.4, label='Confidence Interval')\n",
        "                  plt.title('SARIMA Forecast - Airline Passengers (Next 12 Months)')\n",
        "                  plt.xlabel('Date')\n",
        "                  plt.ylabel('Number of Passengers')\n",
        "                  plt.legend()\n",
        "                  plt.grid(True)\n",
        "                  plt.tight_layout()\n",
        "                  plt.show()\n",
        "\n",
        " Output ;\n",
        "\n",
        "\n",
        "            Forecast Visualization:\n",
        "            Blue Line: Historical monthly passenger data (1949â€“1960)\n",
        "\n",
        "            Green Line: Forecasted values for next 12 months (1961)\n",
        "\n",
        "            Shaded Area: 95% confidence interval\n",
        "\n",
        "             Forecast Highlights (Example Output):\n",
        "            Month\tForecasted Passengers\n",
        "            Jan 1961\t~435\n",
        "            Feb 1961\t~420\n",
        "            ...\t...\n",
        "            Dec 1961\t~495\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "9 Apply Local Outlier Factor (LOF) on any numerical dataset to detect\n",
        "anomalies and visualize them using matplotlib?\n",
        "\n",
        "\n",
        "\n",
        "                    import numpy as np\n",
        "                    import matplotlib.pyplot as plt\n",
        "                    from sklearn.neighbors import LocalOutlierFactor\n",
        "                    from sklearn.datasets import make_blobs\n",
        "\n",
        "                    # Step 1: Create synthetic 2D data with a few outliers\n",
        "                    X, _ = make_blobs(n_samples=300, centers=1, cluster_std=0.60, random_state=42)\n",
        "\n",
        "                    # Add some outliers manually\n",
        "                    np.random.seed(42)\n",
        "                    outliers = np.random.uniform(low=-6, high=6, size=(15, 2))\n",
        "                    X = np.vstack([X, outliers])\n",
        "\n",
        "                    # Step 2: Apply LOF\n",
        "                    lof = LocalOutlierFactor(n_neighbors=20, contamination=0.05)\n",
        "                    y_pred = lof.fit_predict(X)  # -1 = outlier, 1 = inlier\n",
        "                    outlier_scores = -lof.negative_outlier_factor_\n",
        "\n",
        "                    # Step 3: Visualize\n",
        "                    plt.figure(figsize=(10, 6))\n",
        "                    # Plot inliers\n",
        "                    plt.scatter(X[y_pred == 1, 0], X[y_pred == 1, 1],\n",
        "                                c='b', label='Inliers', edgecolors='k', s=60)\n",
        "                    # Plot outliers\n",
        "                    plt.scatter(X[y_pred == -1, 0], X[y_pred == -1, 1],\n",
        "                                c='r', label='Outliers', edgecolors='k', s=60)\n",
        "                    plt.title(\"Local Outlier Factor (LOF) - Anomaly Detection\")\n",
        "                    plt.xlabel(\"Feature 1\")\n",
        "                    plt.ylabel(\"Feature 2\")\n",
        "                    plt.legend()\n",
        "                    plt.grid(True)\n",
        "                    plt.tight_layout()\n",
        "                    plt.show()\n",
        "\n",
        " Output;\n",
        "\n",
        "\n",
        "          Visualization:\n",
        "          Blue points: Inliers (normal observations)\n",
        "\n",
        "          Red points: Detected outliers by LOF\n",
        "\n",
        "          Points are judged anomalous based on local density compared to their neighbors.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        10 You are working as a data scientist for a power grid monitoring company.\n",
        "        Your goal is to forecast energy demand and also detect abnormal spikes or drops in\n",
        "        real-time consumption data collected every 15 minutes. The dataset includes features\n",
        "        like timestamp, region, weather conditions, and energy usage.\n",
        "        Explain your real-time data science workflow:\n",
        "        â— How would you detect anomalies in this streaming data (Isolation Forest / LOF /\n",
        "        DBSCAN)?\n",
        "        â— Which time series model would you use for short-term forecasting (ARIMA /\n",
        "        SARIMA / SARIMAX)?\n",
        "        â— How would you validate and monitor the performance over time?\n",
        "        â— How would this solution help business decisions or operations?\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "          Anomaly Detection in Streaming Data\n",
        "\n",
        "          To detect abnormal spikes or drops in energy consumption, we consider the characteristics of real-time data:\n",
        "\n",
        "          Model\tWhy Itâ€™s Suitable?\n",
        "          Isolation Forest\t Fast, scalable, good for high-dimensional data (with weather, region, etc.)\n",
        "          LOF (Local Outlier Factor)\t Less suitable for streaming (non-incremental, memory-heavy)\n",
        "          DBSCAN\t Computationally expensive, poor with changing densities or streaming data\n",
        "\n",
        "           Chosen Approach:\n",
        "          Isolation Forest\n",
        "\n",
        "          Apply in sliding windows (e.g., 1-hour chunks = 4 data points).\n",
        "\n",
        "          Input features: energy_usage, temperature, humidity, day_of_week, hour.\n",
        "\n",
        "          Detects:\n",
        "\n",
        "          Sudden spikes (e.g., machinery turning on)\n",
        "\n",
        "          Unusual drops (e.g., outages)\n",
        "\n",
        "           2. Short-Term Forecasting of Energy Demand\n",
        "          Options:\n",
        "          Model\tTrend\tSeasonality\tExogenous\tStreaming Suitability\tUse Case\n",
        "          ARIMA\t Batch-only\tBasic forecasting\n",
        "          SARIMA\t Batch-only\tSeasonal demand\n",
        "          SARIMAX\t (but good in pipelines)\tIncludes weather etc.\n",
        "\n",
        "           Chosen Model:\n",
        "          SARIMAX (Seasonal ARIMA with Exogenous variables)\n",
        "\n",
        "          Target: energy_usage\n",
        "\n",
        "          Seasonality: 96 points/day (15 min Ã— 96 = 24h)\n",
        "\n",
        "          Exogenous inputs: Weather data (temperature, humidity), region\n",
        "\n",
        "          Why SARIMAX?\n",
        "\n",
        "          Models both daily/weekly seasonality and weather impacts\n",
        "\n",
        "          Effective for short-term (1â€“24h) load forecasting\n",
        "\n",
        "          Alternative for real-time/online forecasting: Use OnlineARIMA or neural models like Prophet, or deep learning models (LSTM/GRU) wrapped in online retraining pipelines.\n",
        "\n",
        "           3. Validation & Performance Monitoring\n",
        "           Validation Strategy:\n",
        "\n",
        "          Train/test split on historical data:\n",
        "\n",
        "          Last 1 week for test\n",
        "\n",
        "          Use walk-forward validation for robustness\n",
        "\n",
        "          Metrics:\n",
        "\n",
        "          Forecasting: MAE, RMSE, MAPE\n",
        "\n",
        "          Anomaly Detection: Precision, Recall, F1 (compared to labeled anomalies or alerts)\n",
        "\n",
        "           Monitoring in Production:\n",
        "\n",
        "          Dashboards showing:\n",
        "\n",
        "          Forecast vs actuals (line chart)\n",
        "\n",
        "          Anomaly heatmaps per region\n",
        "\n",
        "          Automated alerts:\n",
        "\n",
        "          Sudden deviation > threshold â†’ notify ops team\n",
        "\n",
        "          Retraining frequency:\n",
        "\n",
        "          Every day/week as new data flows in\n",
        "\n",
        "           4. Business Value & Operational Impact\n",
        "          Area\tBenefit\n",
        "          Grid Stability\tDetecting sudden surges/drops helps prevent blackouts or equipment stress\n",
        "          Forecast Accuracy\tBetter short-term forecasting improves load balancing and resource allocation\n",
        "          Cost Optimization\tAnticipate high demand periods â†’ schedule cheaper energy sources\n",
        "          Fault Detection\tOutlier detection can identify equipment failures or data errors\n",
        "          Customer Support\tAlert abnormal usage for customers (smart meters)\n",
        "\n",
        "\n",
        " OUTPUT;\n",
        "\n",
        "\n",
        "          Component\tMethod/Model Used\tJustification\n",
        "          Anomaly Detection\tIsolation Forest (windowed)\tScalable, handles high-dimensional real-time input\n",
        "          Forecasting\tSARIMAX\tHandles seasonality + external weather variables\n",
        "          Validation\tWalk-forward + RMSE/MAE\tTracks forecast accuracy and model drift\n",
        "          Monitoring\tDashboards + Alerts\tReal-time visibility into system behavior\n",
        "          Business Impact\tGrid ops, cost, reliability\tOperational efficiency and proactive grid management\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "yiLKjIYF9vtJ"
      }
    }
  ]
}